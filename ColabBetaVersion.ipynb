{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyVD3AVqg_mT"
      },
      "source": [
        "# **Model Version: 0.1**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vh7_3cunTO9",
        "outputId": "e7b5cfa9-2e2d-4d76-e7fa-a6e1ae891b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c146e5-shGBG"
      },
      "source": [
        "### ***Imports***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWtXTHyDhL1k"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import argparse\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcpi_IJdhLAL"
      },
      "source": [
        "### **Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA3-UdhFhCZN"
      },
      "outputs": [],
      "source": [
        "class TDNN(nn.Module):\n",
        "    \n",
        "    def __init__(\n",
        "                    self, \n",
        "                    input_dim=23, \n",
        "                    output_dim=512,\n",
        "                    context_size=5,\n",
        "                    stride=1,\n",
        "                    dilation=1,\n",
        "                    batch_norm=False,\n",
        "                    dropout_p=0.2\n",
        "                ):\n",
        "        '''\n",
        "        TDNN as defined by https://www.danielpovey.com/files/2015_interspeech_multisplice.pdf\n",
        "\n",
        "        Affine transformation not applied globally to all frames but smaller windows with local context\n",
        "\n",
        "        batch_norm: True to include batch normalisation after the non linearity\n",
        "        \n",
        "        Context size and dilation determine the frames selected\n",
        "        (although context size is not really defined in the traditional sense)\n",
        "        For example:\n",
        "            context size 5 and dilation 1 is equivalent to [-2,-1,0,1,2]\n",
        "            context size 3 and dilation 2 is equivalent to [-2, 0, 2]\n",
        "            context size 1 and dilation 1 is equivalent to [0]\n",
        "        '''\n",
        "        super(TDNN, self).__init__()\n",
        "        self.context_size = context_size\n",
        "        self.stride = stride\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dilation = dilation\n",
        "        self.dropout_p = dropout_p\n",
        "        self.batch_norm = batch_norm\n",
        "      \n",
        "        self.kernel = nn.Linear(input_dim*context_size, output_dim)\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "        if self.batch_norm:\n",
        "            self.bn = nn.BatchNorm1d(output_dim)\n",
        "        if self.dropout_p:\n",
        "            self.drop = nn.Dropout(p=self.dropout_p)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        input: size (batch, seq_len, input_features)\n",
        "        outpu: size (batch, new_seq_len, output_features)\n",
        "        '''\n",
        "        \n",
        "        _, _, d = x.shape\n",
        "        assert (d == self.input_dim), 'Input dimension was wrong. Expected ({}), got ({})'.format(self.input_dim, d)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Unfold input into smaller temporal contexts\n",
        "        x = F.unfold(\n",
        "                        x, \n",
        "                        (self.context_size, self.input_dim), \n",
        "                        stride=(1,self.input_dim), \n",
        "                        dilation=(self.dilation,1)\n",
        "                    )\n",
        "\n",
        "        # N, output_dim*context_size, new_t = x.shape\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.kernel(x.float())\n",
        "        x = self.nonlinearity(x)\n",
        "        \n",
        "        if self.dropout_p:\n",
        "            x = self.drop(x)\n",
        "\n",
        "        if self.batch_norm:\n",
        "            x = x.transpose(1,2)\n",
        "            x = self.bn(x)\n",
        "            x = x.transpose(1,2)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhX96WM1hbCD"
      },
      "outputs": [],
      "source": [
        "class X_vector(nn.Module):\n",
        "    def __init__(self, input_dim = 40, num_classes=8):\n",
        "        super(X_vector, self).__init__()\n",
        "        self.tdnn1 = TDNN(input_dim=input_dim, output_dim=512, context_size=5, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn2 = TDNN(input_dim=512, output_dim=512, context_size=3, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn3 = TDNN(input_dim=512, output_dim=512, context_size=2, dilation=2,dropout_p=0.5)\n",
        "        self.tdnn4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn5 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=3,dropout_p=0.5)\n",
        "        #### Frame levelPooling\n",
        "        self.segment6 = nn.Linear(1024, 512)\n",
        "        self.segment7 = nn.Linear(512, 512)\n",
        "        self.output = nn.Linear(512, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, inputs):\n",
        "        tdnn1_out = self.tdnn1(inputs)\n",
        "        return tdnn1_out\n",
        "        tdnn2_out = self.tdnn2(tdnn1_out)\n",
        "        tdnn3_out = self.tdnn3(tdnn2_out)\n",
        "        tdnn4_out = self.tdnn4(tdnn3_out)\n",
        "        tdnn5_out = self.tdnn5(tdnn4_out)\n",
        "        ### Stat Pool\n",
        "        mean = torch.mean(tdnn5_out,1)\n",
        "        std = torch.std(tdnn5_out,1)\n",
        "        stat_pooling = torch.cat((mean,std),1)\n",
        "        segment6_out = self.segment6(stat_pooling)\n",
        "        x_vec = self.segment7(segment6_out)\n",
        "        predictions = self.softmax(self.output(x_vec))\n",
        "        return predictions,x_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiZdP05khlC3"
      },
      "outputs": [],
      "source": [
        "class X_vector(nn.Module):\n",
        "    def __init__(self, input_dim = 40, num_classes=8):\n",
        "        super(X_vector, self).__init__()\n",
        "        self.tdnn1 = TDNN(input_dim=input_dim, output_dim=512, context_size=5, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn2 = TDNN(input_dim=512, output_dim=512, context_size=3, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn3 = TDNN(input_dim=512, output_dim=512, context_size=2, dilation=2,dropout_p=0.5)\n",
        "        self.tdnn4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn5 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=3,dropout_p=0.5)\n",
        "        #### Frame levelPooling\n",
        "        self.segment6 = nn.Linear(1024, 512)\n",
        "        self.segment7 = nn.Linear(512, 512)\n",
        "        self.output = nn.Linear(512, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, inputs):\n",
        "        tdnn1_out = self.tdnn1(inputs)\n",
        "        tdnn2_out = self.tdnn2(tdnn1_out)\n",
        "        tdnn3_out = self.tdnn3(tdnn2_out)\n",
        "        tdnn4_out = self.tdnn4(tdnn3_out)\n",
        "        tdnn5_out = self.tdnn5(tdnn4_out)\n",
        "        ### Stat Pool\n",
        "        \n",
        "        mean = torch.mean(tdnn5_out,1)\n",
        "        std = torch.var(tdnn5_out,1)\n",
        "        stat_pooling = torch.cat((mean,std),1)\n",
        "        segment6_out = self.segment6(stat_pooling)\n",
        "        x_vec = self.segment7(segment6_out)\n",
        "        predictions = self.output(x_vec)\n",
        "        return predictions,x_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmFsaK-ijzkT"
      },
      "source": [
        "### Utiles "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV8XI7_4jUAH"
      },
      "outputs": [],
      "source": [
        "def load_wav(audio_filepath, sr, min_dur_sec=4):\n",
        "    audio_data,fs  = librosa.load(audio_filepath,sr=16000)\n",
        "    len_file = len(audio_data)\n",
        "    \n",
        "    if len_file <int(min_dur_sec*sr):\n",
        "        dummy=np.zeros((1,int(min_dur_sec*sr)-len_file))\n",
        "        extened_wav = np.concatenate((audio_data,dummy[0]))\n",
        "    else:\n",
        "        \n",
        "        extened_wav = audio_data\n",
        "    return extened_wav\n",
        "\n",
        "\n",
        "def lin_mel_from_wav(wav, hop_length, win_length, n_mels):\n",
        "    linear = librosa.feature.melspectrogram(wav, n_mels=n_mels, win_length=win_length, hop_length=hop_length) # linear spectrogram\n",
        "    return linear.T\n",
        "\n",
        "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=512):\n",
        "    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length) # linear spectrogram\n",
        "    return linear.T\n",
        "\n",
        "\n",
        "def feature_extraction(filepath,sr=16000, min_dur_sec=4,win_length=400,hop_length=160, n_mels=40, spec_len=400,mode='train'):\n",
        "    audio_data = load_wav(filepath, sr=sr,min_dur_sec=min_dur_sec)\n",
        "    linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_fft=512)\n",
        "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
        "    mag_T = mag.T\n",
        "    mu = np.mean(mag_T, 0, keepdims=True)\n",
        "    std = np.std(mag_T, 0, keepdims=True)\n",
        "    return (mag_T - mu) / (std + 1e-5)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "def load_data(filepath,sr=16000, min_dur_sec=4,win_length=400,hop_length=160, n_mels=40, spec_len=400,mode='train'):\n",
        "    audio_data = load_wav(filepath, sr=sr,min_dur_sec=min_dur_sec)\n",
        "    #linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_mels)\n",
        "    linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_fft=512)\n",
        "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
        "    mag_T = mag.T\n",
        "    \n",
        "    if mode=='train':\n",
        "        randtime = np.random.randint(0, mag_T.shape[1]-spec_len)\n",
        "        spec_mag = mag_T[:, randtime:randtime+spec_len]\n",
        "    else:\n",
        "        spec_mag = mag_T\n",
        "    \n",
        "    # preprocessing, subtract mean, divided by time-wise var\n",
        "    mu = np.mean(spec_mag, 0, keepdims=True)\n",
        "    std = np.std(spec_mag, 0, keepdims=True)\n",
        "    return (spec_mag - mu) / (std + 1e-5)\n",
        "    \n",
        "\n",
        "\n",
        "def load_npy_data(filepath,spec_len=400,mode='train'):\n",
        "    mag_T = np.load(filepath)\n",
        "    if mode=='train':\n",
        "        randtime = np.random.randint(0, mag_T.shape[1]-spec_len)\n",
        "        spec_mag = mag_T[:, randtime:randtime+spec_len]\n",
        "    else:\n",
        "        spec_mag = mag_T\n",
        "    return spec_mag\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def speech_collate(batch):\n",
        "    targets = []\n",
        "    specs = []\n",
        "    for sample in batch:\n",
        "        specs.append(sample['features'])\n",
        "        targets.append((sample['labels']))\n",
        "    return specs, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZTJukZ0j4Nr"
      },
      "source": [
        "## SpeechDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjvylivejY_y"
      },
      "outputs": [],
      "source": [
        "class SpeechDataGenerator():\n",
        "    \"\"\"Speech dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, manifest, mode):\n",
        "        \"\"\"\n",
        "        Read the textfile and get the paths\n",
        "        \"\"\"\n",
        "        \n",
        "        # [line.rstrip('\\n').split(' ')[0]\n",
        "        self.mode=mode\n",
        "        self.audio_links = [\" \".join(line.rstrip('\\n').split(' ')[:-1]) for line in open(manifest)]\n",
        "        self.labels = [int(line.rstrip('\\n').split(' ')[-1]) for line in open(manifest)]\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_links)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_link =self.audio_links[idx]\n",
        "        class_id = self.labels[idx]\n",
        "        #lang_label=lang_id[self.audio_links[idx].split('/')[-2]]\n",
        "        spec = load_data(audio_link,mode=self.mode)\n",
        "        sample = {'features': torch.from_numpy(np.ascontiguousarray(spec)), 'labels': torch.from_numpy(np.ascontiguousarray(class_id))}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZM6lFNOlwL6"
      },
      "source": [
        "## Train X Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idauk9yWlyJs"
      },
      "outputs": [],
      "source": [
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "\n",
        "########## Argument parser\n",
        "\n",
        "training_filepath = '/content/drive/My Drive/meta/training.txt'\n",
        "testing_filepath = '/content/drive/My Drive/meta/testing.txt'\n",
        "validation_filepath = '/content/drive/My Drive/meta/validation.txt'\n",
        "input_dim = 257\n",
        "num_classes = 9\n",
        "lamda_val = 0.5\n",
        "batch_size = 10\n",
        "use_gpu = True\n",
        "num_epochs = 30\n",
        "# parser = argparse.ArgumentParser(add_help=False)\n",
        "# parser.add_argument('-training_filepath', type=str, default='/content/drive/My Drive/meta/training.txt')\n",
        "# parser.add_argument('-testing_filepath', type=str, default='/content/drive/My Drive/meta/testing.txt')\n",
        "# parser.add_argument('-validation_filepath', type=str, default='/content/drive/My Drive/meta/validation.txt')\n",
        "\n",
        "# parser.add_argument('-input_dim', action=\"store_true\", default=257)\n",
        "# parser.add_argument('-num_classes', action=\"store_true\", default=9)\n",
        "# parser.add_argument('-lamda_val', action=\"store_true\", default=0.5)\n",
        "# parser.add_argument('-batch_size', action=\"store_true\", default=10)\n",
        "# parser.add_argument('-use_gpu', action=\"store_true\", default=True)\n",
        "# parser.add_argument('-num_epochs', action=\"store_true\", default=30)\n",
        "#args = parser.parse_args()\n",
        "\n",
        "### Data related\n",
        "dataset_train = SpeechDataGenerator(manifest=training_filepath, mode='train')\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n",
        "\n",
        "dataset_val = SpeechDataGenerator(manifest=validation_filepath, mode='train')\n",
        "dataloader_val = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n",
        "\n",
        "dataset_test = SpeechDataGenerator(manifest=testing_filepath, mode='test')\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n",
        "\n",
        "## Model related\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = X_vector(input_dim, num_classes).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train(dataloader_train, epoch):\n",
        "    train_loss_list = []\n",
        "    full_preds = []\n",
        "    full_gts = []\n",
        "    model.train()\n",
        "\n",
        "    for i_batch, sample_batched in enumerate(dataloader_train):\n",
        "        print(\"batch: \" + str(i_batch+1))\n",
        "        features = torch.from_numpy(np.asarray([torch_tensor.numpy().T for torch_tensor in sample_batched[0]])).float()\n",
        "        labels = torch.from_numpy(np.asarray([torch_tensor[0].numpy() for torch_tensor in sample_batched[1]]))\n",
        "        labels = labels.long()\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "        features.requires_grad = True\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits, x_vec = model(features)\n",
        "        #### CE loss\n",
        "        loss = loss_fun(pred_logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_list.append(loss.item())\n",
        "        # train_acc_list.append(accuracy)\n",
        "        # if i_batch%10==0:\n",
        "        #    print('Loss {} after {} iteration'.format(np.mean(np.asarray(train_loss_list)),i_batch))\n",
        "\n",
        "        predictions = np.argmax(pred_logits.detach().cpu().numpy(), axis=1)\n",
        "        for pred in predictions:\n",
        "            full_preds.append(pred)\n",
        "        for lab in labels.detach().cpu().numpy():\n",
        "            full_gts.append(lab)\n",
        "\n",
        "    mean_acc = accuracy_score(full_gts, full_preds)\n",
        "    mean_loss = np.mean(np.asarray(train_loss_list))\n",
        "    print('Total training loss {} and training Accuracy {} after {} epochs'.format(mean_loss, mean_acc, epoch))\n",
        "\n",
        "\n",
        "def validation(dataloader_val, epoch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss_list = []\n",
        "        full_preds = []\n",
        "        full_gts = []\n",
        "        for i_batch, sample_batched in enumerate(dataloader_val):\n",
        "            features = torch.from_numpy(\n",
        "                np.asarray([torch_tensor.numpy().T for torch_tensor in sample_batched[0]])).float()\n",
        "            labels = torch.from_numpy(np.asarray([torch_tensor[0].numpy() for torch_tensor in sample_batched[1]]))\n",
        "            labels = labels.long()\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            pred_logits, x_vec = model(features)\n",
        "            #### CE loss\n",
        "            loss = loss_fun(pred_logits, labels)\n",
        "            val_loss_list.append(loss.item())\n",
        "            # train_acc_list.append(accuracy)\n",
        "            predictions = np.argmax(pred_logits.detach().cpu().numpy(), axis=1)\n",
        "            for pred in predictions:\n",
        "                full_preds.append(pred)\n",
        "            for lab in labels.detach().cpu().numpy():\n",
        "                full_gts.append(lab)\n",
        "\n",
        "        mean_acc = accuracy_score(full_gts, full_preds)\n",
        "        mean_loss = np.mean(np.asarray(val_loss_list))\n",
        "        print('Total validation loss {} and Validation accuracy {} after {} epochs'.format(mean_loss, mean_acc, epoch))\n",
        "\n",
        "        # TODO: CHANGE BACK TO SAVE MODEL:\n",
        "        # model_save_path = os.path.join('save_model', 'best_check_point_' + str(epoch) + '_' + str(mean_loss))\n",
        "        # state_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}\n",
        "        # torch.save(state_dict, model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi0DAtGGncLE",
        "outputId": "094382a8-4d70-4ede-db0b-f6deec3f9376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 1.966078437699212 and training Accuracy 0.21555555555555556 after 0 epochs\n",
            "Total validation loss 1.5570416351159413 and Validation accuracy 0.39444444444444443 after 0 epochs\n",
            "2\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 1.3559307648075951 and training Accuracy 0.46111111111111114 after 1 epochs\n",
            "Total validation loss 1.2857302559746637 and Validation accuracy 0.49333333333333335 after 1 epochs\n",
            "3\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 1.0536217699448267 and training Accuracy 0.5888888888888889 after 2 epochs\n",
            "Total validation loss 1.1051338685883416 and Validation accuracy 0.4633333333333333 after 2 epochs\n",
            "4\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.8894798654648993 and training Accuracy 0.66 after 3 epochs\n",
            "Total validation loss 0.824574462738302 and Validation accuracy 0.71 after 3 epochs\n",
            "5\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.8098748251795769 and training Accuracy 0.71 after 4 epochs\n",
            "Total validation loss 0.9322896675931083 and Validation accuracy 0.61 after 4 epochs\n",
            "6\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.5857598757578267 and training Accuracy 0.7966666666666666 after 5 epochs\n",
            "Total validation loss 0.9075821133123504 and Validation accuracy 0.6977777777777778 after 5 epochs\n",
            "7\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.5929787624213431 and training Accuracy 0.8066666666666666 after 6 epochs\n",
            "Total validation loss 0.7467102772659726 and Validation accuracy 0.7422222222222222 after 6 epochs\n",
            "8\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.5449678106440439 and training Accuracy 0.8188888888888889 after 7 epochs\n",
            "Total validation loss 0.6522056382563379 and Validation accuracy 0.7411111111111112 after 7 epochs\n",
            "9\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.475333823462198 and training Accuracy 0.8466666666666667 after 8 epochs\n",
            "Total validation loss 0.4653886627819803 and Validation accuracy 0.8244444444444444 after 8 epochs\n",
            "10\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.43008262374334866 and training Accuracy 0.8733333333333333 after 9 epochs\n",
            "Total validation loss 0.409181745764282 and Validation accuracy 0.86 after 9 epochs\n",
            "11\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.36582129281014203 and training Accuracy 0.8866666666666667 after 10 epochs\n",
            "Total validation loss 0.6118570481737454 and Validation accuracy 0.7688888888888888 after 10 epochs\n",
            "12\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.39073951839074855 and training Accuracy 0.8711111111111111 after 11 epochs\n",
            "Total validation loss 0.393822159887188 and Validation accuracy 0.8711111111111111 after 11 epochs\n",
            "13\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.5448399424552918 and training Accuracy 0.8633333333333333 after 12 epochs\n",
            "Total validation loss 0.7599899155812131 and Validation accuracy 0.7422222222222222 after 12 epochs\n",
            "14\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.21770026397425682 and training Accuracy 0.9255555555555556 after 13 epochs\n",
            "Total validation loss 0.5460284846990059 and Validation accuracy 0.86 after 13 epochs\n",
            "15\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.24342500660309774 and training Accuracy 0.9244444444444444 after 14 epochs\n",
            "Total validation loss 0.2989427894974748 and Validation accuracy 0.9011111111111111 after 14 epochs\n",
            "16\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.41843553216118984 and training Accuracy 0.8888888888888888 after 15 epochs\n",
            "Total validation loss 0.33171422835439446 and Validation accuracy 0.9022222222222223 after 15 epochs\n",
            "17\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.6206589833471097 and training Accuracy 0.8755555555555555 after 16 epochs\n",
            "Total validation loss 0.3311581509394778 and Validation accuracy 0.9088888888888889 after 16 epochs\n",
            "18\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.18193451402605407 and training Accuracy 0.9355555555555556 after 17 epochs\n",
            "Total validation loss 0.31461212048307063 and Validation accuracy 0.9055555555555556 after 17 epochs\n",
            "19\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.21442612315424614 and training Accuracy 0.94 after 18 epochs\n",
            "Total validation loss 0.29161567948758604 and Validation accuracy 0.8977777777777778 after 18 epochs\n",
            "20\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.2454941428421686 and training Accuracy 0.9277777777777778 after 19 epochs\n",
            "Total validation loss 0.3824594697190656 and Validation accuracy 0.8277777777777777 after 19 epochs\n",
            "21\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.2235521483372496 and training Accuracy 0.9266666666666666 after 20 epochs\n",
            "Total validation loss 0.5440326157543395 and Validation accuracy 0.8188888888888889 after 20 epochs\n",
            "22\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.21568821320300532 and training Accuracy 0.9311111111111111 after 21 epochs\n",
            "Total validation loss 0.31005757295837005 and Validation accuracy 0.8877777777777778 after 21 epochs\n",
            "23\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.24140959846554325 and training Accuracy 0.9233333333333333 after 22 epochs\n",
            "Total validation loss 0.2401539814011711 and Validation accuracy 0.9111111111111111 after 22 epochs\n",
            "24\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.25299020967003244 and training Accuracy 0.9333333333333333 after 23 epochs\n",
            "Total validation loss 0.18979060522979124 and Validation accuracy 0.9366666666666666 after 23 epochs\n",
            "25\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.35340991093722146 and training Accuracy 0.92 after 24 epochs\n",
            "Total validation loss 0.2574621279620462 and Validation accuracy 0.9233333333333333 after 24 epochs\n",
            "26\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.1952684124142656 and training Accuracy 0.9377777777777778 after 25 epochs\n",
            "Total validation loss 0.3230307042443504 and Validation accuracy 0.9077777777777778 after 25 epochs\n",
            "27\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.3390095913834456 and training Accuracy 0.9122222222222223 after 26 epochs\n",
            "Total validation loss 0.27194388506727085 and Validation accuracy 0.9066666666666666 after 26 epochs\n",
            "28\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.23089457512291522 and training Accuracy 0.9355555555555556 after 27 epochs\n",
            "Total validation loss 0.34678021849443513 and Validation accuracy 0.8933333333333333 after 27 epochs\n",
            "29\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.16809554786143255 and training Accuracy 0.9533333333333334 after 28 epochs\n",
            "Total validation loss 0.17716930331662298 and Validation accuracy 0.9377777777777778 after 28 epochs\n",
            "30\n",
            "batch: 1\n",
            "batch: 2\n",
            "batch: 3\n",
            "batch: 4\n",
            "batch: 5\n",
            "batch: 6\n",
            "batch: 7\n",
            "batch: 8\n",
            "batch: 9\n",
            "batch: 10\n",
            "batch: 11\n",
            "batch: 12\n",
            "batch: 13\n",
            "batch: 14\n",
            "batch: 15\n",
            "batch: 16\n",
            "batch: 17\n",
            "batch: 18\n",
            "batch: 19\n",
            "batch: 20\n",
            "batch: 21\n",
            "batch: 22\n",
            "batch: 23\n",
            "batch: 24\n",
            "batch: 25\n",
            "batch: 26\n",
            "batch: 27\n",
            "batch: 28\n",
            "batch: 29\n",
            "batch: 30\n",
            "batch: 31\n",
            "batch: 32\n",
            "batch: 33\n",
            "batch: 34\n",
            "batch: 35\n",
            "batch: 36\n",
            "batch: 37\n",
            "batch: 38\n",
            "batch: 39\n",
            "batch: 40\n",
            "batch: 41\n",
            "batch: 42\n",
            "batch: 43\n",
            "batch: 44\n",
            "batch: 45\n",
            "batch: 46\n",
            "batch: 47\n",
            "batch: 48\n",
            "batch: 49\n",
            "batch: 50\n",
            "batch: 51\n",
            "batch: 52\n",
            "batch: 53\n",
            "batch: 54\n",
            "batch: 55\n",
            "batch: 56\n",
            "batch: 57\n",
            "batch: 58\n",
            "batch: 59\n",
            "batch: 60\n",
            "batch: 61\n",
            "batch: 62\n",
            "batch: 63\n",
            "batch: 64\n",
            "batch: 65\n",
            "batch: 66\n",
            "batch: 67\n",
            "batch: 68\n",
            "batch: 69\n",
            "batch: 70\n",
            "batch: 71\n",
            "batch: 72\n",
            "batch: 73\n",
            "batch: 74\n",
            "batch: 75\n",
            "batch: 76\n",
            "batch: 77\n",
            "batch: 78\n",
            "batch: 79\n",
            "batch: 80\n",
            "batch: 81\n",
            "batch: 82\n",
            "batch: 83\n",
            "batch: 84\n",
            "batch: 85\n",
            "batch: 86\n",
            "batch: 87\n",
            "batch: 88\n",
            "batch: 89\n",
            "batch: 90\n",
            "Total training loss 0.29898395656960525 and training Accuracy 0.9444444444444444 after 29 epochs\n",
            "Total validation loss 0.38136602801581226 and Validation accuracy 0.8755555555555555 after 29 epochs\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(epoch+1)\n",
        "    train(dataloader_train, epoch)\n",
        "    validation(dataloader_val, epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generator "
      ],
      "metadata": {
        "id": "1RWBaWK0Ea44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yklDKqSSFID-",
        "outputId": "b2ff38d8-8e1d-473c-e24c-1ec7993b9ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ],
      "metadata": {
        "id": "ro95Bh3aEeQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_audio(audio_data, sr, n_steps=None, noise_mean=0., noise_std=None, speed_rate=None):\n",
        "    if n_steps is not None:\n",
        "        audio_data = librosa.effects.pitch_shift(audio_data, sr=sr, n_steps=n_steps)\n",
        "    if noise_std is not None:\n",
        "        noise = np.random.normal(noise_mean, noise_std, audio_data.shape)\n",
        "        audio_data = np.clip(audio_data + noise, -1., 1.)\n",
        "    if speed_rate is not None:\n",
        "        audio_data = librosa.effects.time_stretch(audio_data, rate=speed_rate)\n",
        "    return audio_data\n",
        "\n",
        "\n",
        "def reduce_noise(audio_file_path):\n",
        "    audio_file = AudioSegment.from_wav(audio_file_path)\n",
        "    chunks = split_on_silence(audio_file, min_silence_len=1000, silence_thresh=-40)\n",
        "    selected_chunks = [chunk for chunk in chunks if len(chunk) > 0]\n",
        "    new_audio = selected_chunks[0]\n",
        "    for chunk in selected_chunks[1:]:\n",
        "        new_audio += chunk\n",
        "    new_audio.export(audio_file_path, format='wav')\n",
        "\n",
        "\n",
        "def convert_transform_and_reduce_noise(file_path):\n",
        "    # Convert to WAV\n",
        "    sound = AudioSegment.from_mp3(file_path)\n",
        "    fname_without_ext = os.path.splitext(file_path)[0]\n",
        "    wav_path = f\"{fname_without_ext}.wav\"\n",
        "    sound.export(wav_path, format=\"wav\")\n",
        "    os.remove(file_path)  # delete original file\n",
        "\n",
        "    # Reduce noise\n",
        "    reduce_noise(wav_path)\n",
        "\n",
        "    # Load WAV and transform audio\n",
        "    audio_data, sr = librosa.load(wav_path, sr=None)\n",
        "    audio_data_transformed = transform_audio(\n",
        "        audio_data, sr, n_steps=0, noise_mean=0., noise_std=0.00, speed_rate=1\n",
        "    )\n",
        "    output_filename = f\"{fname_without_ext}_Original.wav\"\n",
        "    sf.write(output_filename, audio_data_transformed, sr)\n",
        "\n",
        "    random_float = round(random.uniform(0.00, 0.10), 2)\n",
        "    audio_data_transformed_noise = transform_audio(\n",
        "        audio_data, sr, n_steps=0, noise_mean=0., noise_std=random_float, speed_rate=1\n",
        "    )\n",
        "    output_filename = f\"{fname_without_ext}_noise_{random_float}.wav\"\n",
        "    sf.write(output_filename, audio_data_transformed_noise, sr)\n",
        "\n",
        "    random_float = round(random.uniform(1.0, 1.6), 2)\n",
        "    audio_data_transformed_speed = transform_audio(\n",
        "        audio_data, sr, n_steps=0, noise_mean=0., noise_std=0.00, speed_rate=random_float\n",
        "    )\n",
        "    output_filename = f\"{fname_without_ext}_speed_{random_float}.wav\"\n",
        "    sf.write(output_filename, audio_data_transformed_speed, sr)\n",
        "\n",
        "    random_float = round(random.uniform(1.0, 3.0), 2)\n",
        "    audio_data_transformed_pitch = transform_audio(\n",
        "        audio_data, sr, n_steps=random_float, noise_mean=0., noise_std=0.00, speed_rate=1\n",
        "    )\n",
        "    output_filename = f\"{fname_without_ext}_pitch_{random_float}.wav\"\n",
        "    sf.write(output_filename, audio_data_transformed_pitch, sr)\n",
        "\n",
        "\n",
        "    random_float = round(random.uniform(0.00, 0.10), 2)\n",
        "    random_float1 = round(random.uniform(1.0, 1.6), 2)\n",
        "    random_float2 = round(random.uniform(1.0, 3.0), 2)\n",
        "    audio_data_transformed_all = transform_audio(\n",
        "        audio_data, sr, n_steps=random_float, noise_mean=0., noise_std=0.00, speed_rate=1\n",
        "    )\n",
        "    output_filename = f\"{fname_without_ext}_noise_{random_float}_speed_{random_float1}_pitch_{random_float2}.wav\"\n",
        "    sf.write(output_filename, audio_data_transformed_all, sr)\n",
        "\n",
        "    return 1\n",
        "\n",
        "\n",
        "def load(path):\n",
        "    counter = 0\n",
        "    mp3_files = []\n",
        "    for dirName, subdirList, fileList in os.walk(path):\n",
        "        print(f'Found directory: {dirName}')\n",
        "        for fname in fileList:\n",
        "            if fname.endswith('.mp3'):\n",
        "                mp3_files.append(os.path.join(dirName, fname))\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        results = executor.map(convert_transform_and_reduce_noise, mp3_files)\n",
        "        counter = sum(results)\n",
        "\n",
        "    print('=============================')\n",
        "    print(f'Total Data files loaded: {counter}')\n",
        "    print('=============================')"
      ],
      "metadata": {
        "id": "-YxcrQxdFLq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    rootDir = 'C:\\\\Users\\\\koazg\\\\Desktop\\\\same_size_lang'\n",
        "    load(rootDir)"
      ],
      "metadata": {
        "id": "3YGlnOuqFsna"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c146e5-shGBG",
        "rcpi_IJdhLAL",
        "UmFsaK-ijzkT",
        "FZTJukZ0j4Nr"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}