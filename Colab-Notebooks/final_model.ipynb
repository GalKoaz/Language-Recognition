{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyVD3AVqg_mT"
      },
      "source": [
        "# **Model Version: 0.1**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vh7_3cunTO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41225099-77ca-4a6d-ccb7-3e0c889417ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c146e5-shGBG"
      },
      "source": [
        "### ***Imports***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWtXTHyDhL1k"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import argparse\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcpi_IJdhLAL"
      },
      "source": [
        "### **Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA3-UdhFhCZN"
      },
      "outputs": [],
      "source": [
        "class TDNN(nn.Module):\n",
        "    \n",
        "    def __init__(\n",
        "                    self, \n",
        "                    input_dim=23, \n",
        "                    output_dim=512,\n",
        "                    context_size=5,\n",
        "                    stride=1,\n",
        "                    dilation=1,\n",
        "                    batch_norm=False,\n",
        "                    dropout_p=0.2\n",
        "                ):\n",
        "        '''\n",
        "        TDNN as defined by https://www.danielpovey.com/files/2015_interspeech_multisplice.pdf\n",
        "\n",
        "        Affine transformation not applied globally to all frames but smaller windows with local context\n",
        "\n",
        "        batch_norm: True to include batch normalisation after the non linearity\n",
        "        \n",
        "        Context size and dilation determine the frames selected\n",
        "        (although context size is not really defined in the traditional sense)\n",
        "        For example:\n",
        "            context size 5 and dilation 1 is equivalent to [-2,-1,0,1,2]\n",
        "            context size 3 and dilation 2 is equivalent to [-2, 0, 2]\n",
        "            context size 1 and dilation 1 is equivalent to [0]\n",
        "        '''\n",
        "        super(TDNN, self).__init__()\n",
        "        self.context_size = context_size\n",
        "        self.stride = stride\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dilation = dilation\n",
        "        self.dropout_p = dropout_p\n",
        "        self.batch_norm = batch_norm\n",
        "      \n",
        "        self.kernel = nn.Linear(input_dim*context_size, output_dim)\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "        if self.batch_norm:\n",
        "            self.bn = nn.BatchNorm1d(output_dim)\n",
        "        if self.dropout_p:\n",
        "            self.drop = nn.Dropout(p=self.dropout_p)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        input: size (batch, seq_len, input_features)\n",
        "        outpu: size (batch, new_seq_len, output_features)\n",
        "        '''\n",
        "        \n",
        "        _, _, d = x.shape\n",
        "        assert (d == self.input_dim), 'Input dimension was wrong. Expected ({}), got ({})'.format(self.input_dim, d)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # Unfold input into smaller temporal contexts\n",
        "        x = F.unfold(\n",
        "                        x, \n",
        "                        (self.context_size, self.input_dim), \n",
        "                        stride=(1,self.input_dim), \n",
        "                        dilation=(self.dilation,1)\n",
        "                    )\n",
        "\n",
        "        # N, output_dim*context_size, new_t = x.shape\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.kernel(x.float())\n",
        "        x = self.nonlinearity(x)\n",
        "        \n",
        "        if self.dropout_p:\n",
        "            x = self.drop(x)\n",
        "\n",
        "        if self.batch_norm:\n",
        "            x = x.transpose(1,2)\n",
        "            x = self.bn(x)\n",
        "            x = x.transpose(1,2)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhX96WM1hbCD"
      },
      "outputs": [],
      "source": [
        "class X_vector(nn.Module):\n",
        "    def __init__(self, input_dim = 40, num_classes=10):\n",
        "        super(X_vector, self).__init__()\n",
        "        self.tdnn1 = TDNN(input_dim=input_dim, output_dim=1280, context_size=3, dilation=2,dropout_p=0.5)\n",
        "        self.tdnn2 = TDNN(input_dim=1280, output_dim=1280, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn3 = TDNN(input_dim=1280, output_dim=1024, context_size=5, dilation=2,dropout_p=0.5)\n",
        "        self.tdnn4 = TDNN(input_dim=1024, output_dim=1024, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn5 = TDNN(input_dim=1024, output_dim=768, context_size=2, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn6 = TDNN(input_dim=768, output_dim=512, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn7 = TDNN(input_dim=512, output_dim=256, context_size=1, dilation=3,dropout_p=0.5)\n",
        "        #### Frame levelPooling\n",
        "        self.segment8 = nn.Linear(512, 512)\n",
        "        self.segment9 = nn.Linear(512, 512)\n",
        "        self.output = nn.Linear(512, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, inputs):\n",
        "        tdnn1_out = self.tdnn1(inputs)\n",
        "        return tdnn1_out\n",
        "        tdnn2_out = self.tdnn2(tdnn1_out)\n",
        "        tdnn3_out = self.tdnn3(tdnn2_out)\n",
        "        tdnn4_out = self.tdnn4(tdnn3_out)\n",
        "        tdnn5_out = self.tdnn5(tdnn4_out)\n",
        "        tdnn6_out = self.tdnn6(tdnn5_out)\n",
        "        tdnn7_out = self.tdnn7(tdnn6_out)\n",
        "        ### Stat Pool\n",
        "        mean = torch.mean(tdnn7_out,1)\n",
        "        std = torch.std(tdnn7_out,1)\n",
        "        stat_pooling = torch.cat((mean,std),1)\n",
        "        segment8_out = self.segment8(stat_pooling)\n",
        "        x_vec = self.segment9(segment8_out)\n",
        "        predictions = self.softmax(self.output(x_vec))\n",
        "        return predictions,x_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiZdP05khlC3"
      },
      "outputs": [],
      "source": [
        "class X_vector(nn.Module):\n",
        "    def __init__(self, input_dim = 40, num_classes=10):\n",
        "        super(X_vector, self).__init__()\n",
        "        self.tdnn1 = TDNN(input_dim=input_dim, output_dim=1280, context_size=3, dilation=2,dropout_p=0.5)\n",
        "        self.tdnn2 = TDNN(input_dim=1280, output_dim=1280, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn3 = TDNN(input_dim=1280, output_dim=1024, context_size=5, dilation=2,dropout_p=0.5)\n",
        "        self.tdnn4 = TDNN(input_dim=1024, output_dim=1024, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn5 = TDNN(input_dim=1024, output_dim=768, context_size=2, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn6 = TDNN(input_dim=768, output_dim=512, context_size=1, dilation=1,dropout_p=0.5)\n",
        "        self.tdnn7 = TDNN(input_dim=512, output_dim=256, context_size=1, dilation=3,dropout_p=0.5)\n",
        "        #### Frame levelPooling\n",
        "        self.segment8 = nn.Linear(512, 512)\n",
        "        self.segment9 = nn.Linear(512, 512)\n",
        "        self.output = nn.Linear(512, num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, inputs):\n",
        "        tdnn1_out = self.tdnn1(inputs)\n",
        "        tdnn2_out = self.tdnn2(tdnn1_out)\n",
        "        tdnn3_out = self.tdnn3(tdnn2_out)\n",
        "        tdnn4_out = self.tdnn4(tdnn3_out)\n",
        "        tdnn5_out = self.tdnn5(tdnn4_out)\n",
        "        tdnn6_out = self.tdnn6(tdnn5_out)\n",
        "        tdnn7_out = self.tdnn7(tdnn6_out)\n",
        "        ### Stat Pool\n",
        "        \n",
        "        mean = torch.mean(tdnn7_out,1)\n",
        "        std = torch.std(tdnn7_out,1)\n",
        "        stat_pooling = torch.cat((mean,std),1)\n",
        "        segment8_out = self.segment8(stat_pooling)\n",
        "        x_vec = self.segment9(segment8_out)\n",
        "        predictions = self.output(x_vec)\n",
        "        return predictions,x_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmFsaK-ijzkT"
      },
      "source": [
        "### Utiles "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV8XI7_4jUAH"
      },
      "outputs": [],
      "source": [
        "def load_wav(audio_filepath, sr, min_dur_sec=4):\n",
        "    audio_data,fs  = librosa.load(audio_filepath,sr=16000)\n",
        "    len_file = len(audio_data)\n",
        "    \n",
        "    if len_file <int(min_dur_sec*sr):\n",
        "        dummy=np.zeros((1,int(min_dur_sec*sr)-len_file))\n",
        "        extened_wav = np.concatenate((audio_data,dummy[0]))\n",
        "    else:\n",
        "        \n",
        "        extened_wav = audio_data\n",
        "    return extened_wav\n",
        "\n",
        "\n",
        "def lin_mel_from_wav(wav, hop_length, win_length, n_mels):\n",
        "    linear = librosa.feature.melspectrogram(wav, n_mels=n_mels, win_length=win_length, hop_length=hop_length) # linear spectrogram\n",
        "    return linear.T\n",
        "\n",
        "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=512):\n",
        "    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length) # linear spectrogram\n",
        "    return linear.T\n",
        "\n",
        "\n",
        "def feature_extraction(filepath,sr=16000, min_dur_sec=4,win_length=400,hop_length=160, n_mels=40, spec_len=400,mode='train'):\n",
        "    audio_data = load_wav(filepath, sr=sr,min_dur_sec=min_dur_sec)\n",
        "    linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_fft=512)\n",
        "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
        "    mag_T = mag.T\n",
        "    mu = np.mean(mag_T, 0, keepdims=True)\n",
        "    std = np.std(mag_T, 0, keepdims=True)\n",
        "    return (mag_T - mu) / (std + 1e-5)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "def load_data(filepath,sr=16000, min_dur_sec=4,win_length=400,hop_length=160, n_mels=40, spec_len=400,mode='train'):\n",
        "    audio_data = load_wav(filepath, sr=sr,min_dur_sec=min_dur_sec)\n",
        "    #linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_mels)\n",
        "    linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_fft=512)\n",
        "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
        "    mag_T = mag.T\n",
        "    \n",
        "    if mode=='train':\n",
        "        randtime = np.random.randint(0, mag_T.shape[1]-spec_len)\n",
        "        spec_mag = mag_T[:, randtime:randtime+spec_len]\n",
        "    else:\n",
        "        spec_mag = mag_T\n",
        "    \n",
        "    # preprocessing, subtract mean, divided by time-wise var\n",
        "    mu = np.mean(spec_mag, 0, keepdims=True)\n",
        "    std = np.std(spec_mag, 0, keepdims=True)\n",
        "    return (spec_mag - mu) / (std + 1e-5)\n",
        "    \n",
        "\n",
        "\n",
        "def load_npy_data(filepath,spec_len=400,mode='train'):\n",
        "    mag_T = np.load(filepath)\n",
        "    if mode=='train':\n",
        "        randtime = np.random.randint(0, mag_T.shape[1]-spec_len)\n",
        "        spec_mag = mag_T[:, randtime:randtime+spec_len]\n",
        "    else:\n",
        "        spec_mag = mag_T\n",
        "    return spec_mag\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def speech_collate(batch):\n",
        "    targets = []\n",
        "    specs = []\n",
        "    for sample in batch:\n",
        "        specs.append(sample['features'])\n",
        "        targets.append((sample['labels']))\n",
        "    return specs, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZTJukZ0j4Nr"
      },
      "source": [
        "## SpeechDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjvylivejY_y"
      },
      "outputs": [],
      "source": [
        "class SpeechDataGenerator():\n",
        "    \"\"\"Speech dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, manifest, mode):\n",
        "        \"\"\"\n",
        "        Read the textfile and get the paths\n",
        "        \"\"\"\n",
        "        \n",
        "        # [line.rstrip('\\n').split(' ')[0]\n",
        "        self.mode=mode\n",
        "        self.audio_links = [\" \".join(line.rstrip('\\n').split(' ')[:-1]) for line in open(manifest)]\n",
        "        self.labels = [int(line.rstrip('\\n').split(' ')[-1]) for line in open(manifest)]\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_links)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_link =self.audio_links[idx]\n",
        "        class_id = self.labels[idx]\n",
        "        #lang_label=lang_id[self.audio_links[idx].split('/')[-2]]\n",
        "        spec = load_data(audio_link,mode=self.mode)\n",
        "        sample = {'features': torch.from_numpy(np.ascontiguousarray(spec)), 'labels': torch.from_numpy(np.ascontiguousarray(class_id))}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZM6lFNOlwL6"
      },
      "source": [
        "## Train X Vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idauk9yWlyJs"
      },
      "outputs": [],
      "source": [
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "\n",
        "########## Argument parser\n",
        "\n",
        "training_filepath = '/content/drive/My Drive/10_lang_wav_files/train_10_lang.txt'\n",
        "testing_filepath = '/content/drive/My Drive/10_lang_wav_files/test_10_lang.txt'\n",
        "validation_filepath = '/content/drive/My Drive/10_lang_wav_files/validation_10_lang.txt'\n",
        "input_dim = 257\n",
        "num_classes = 10\n",
        "lamda_val = 0.5\n",
        "batch_size = 100\n",
        "use_gpu = True\n",
        "num_epochs = 100\n",
        "\n",
        "### Data related\n",
        "dataset_train = SpeechDataGenerator(manifest=training_filepath, mode='train')\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n",
        "\n",
        "dataset_val = SpeechDataGenerator(manifest=validation_filepath, mode='train')\n",
        "dataloader_val = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n",
        "\n",
        "dataset_test = SpeechDataGenerator(manifest=testing_filepath, mode='test')\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n",
        "\n",
        "## Model related\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = X_vector(input_dim, num_classes).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train(dataloader_train, epoch):\n",
        "    train_loss_list = []\n",
        "    full_preds = []\n",
        "    full_gts = []\n",
        "    model.train()\n",
        "\n",
        "    print(\"batch: \")\n",
        "    for i_batch, sample_batched in enumerate(dataloader_train):\n",
        "        print(str(i_batch+1)+\" \", end='')\n",
        "\n",
        "        features = torch.from_numpy(np.asarray([torch_tensor.numpy().T for torch_tensor in sample_batched[0]])).float()\n",
        "        labels = torch.from_numpy(np.asarray([torch_tensor[0].numpy() for torch_tensor in sample_batched[1]]))\n",
        "        labels = labels.long()\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "        features.requires_grad = True\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits, x_vec = model(features)\n",
        "        #### CE loss\n",
        "        loss = loss_fun(pred_logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_list.append(loss.item())\n",
        "        # train_acc_list.append(accuracy)\n",
        "        # if i_batch%10==0:\n",
        "        #    print('Loss {} after {} iteration'.format(np.mean(np.asarray(train_loss_list)),i_batch))\n",
        "\n",
        "        predictions = np.argmax(pred_logits.detach().cpu().numpy(), axis=1)\n",
        "        for pred in predictions:\n",
        "            full_preds.append(pred)\n",
        "        for lab in labels.detach().cpu().numpy():\n",
        "            full_gts.append(lab)\n",
        "\n",
        "    mean_acc = accuracy_score(full_gts, full_preds)\n",
        "    mean_loss = np.mean(np.asarray(train_loss_list))\n",
        "    print('Total training loss {} and training Accuracy {} after {} epochs'.format(mean_loss, mean_acc, epoch))\n",
        "\n",
        "    folder_path = '/content/drive/My Drive/saved_models'\n",
        "    model_save_path = f'{folder_path}/saved_model_{i_batch}.pth'\n",
        "    state_dict = {\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'epoch': num_epochs\n",
        "    }\n",
        "    torch.save(state_dict, model_save_path)\n",
        "\n",
        "\n",
        "def validation(dataloader_val, epoch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss_list = []\n",
        "        full_preds = []\n",
        "        full_gts = []\n",
        "        for i_batch, sample_batched in enumerate(dataloader_val):\n",
        "            features = torch.from_numpy(\n",
        "                np.asarray([torch_tensor.numpy().T for torch_tensor in sample_batched[0]])).float()\n",
        "            labels = torch.from_numpy(np.asarray([torch_tensor[0].numpy() for torch_tensor in sample_batched[1]]))\n",
        "            labels = labels.long()\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            pred_logits, x_vec = model(features)\n",
        "            #### CE loss\n",
        "            loss = loss_fun(pred_logits, labels)\n",
        "            val_loss_list.append(loss.item())\n",
        "            # train_acc_list.append(accuracy)\n",
        "            predictions = np.argmax(pred_logits.detach().cpu().numpy(), axis=1)\n",
        "            for pred in predictions:\n",
        "                full_preds.append(pred)\n",
        "            for lab in labels.detach().cpu().numpy():\n",
        "                full_gts.append(lab)\n",
        "\n",
        "        mean_acc = accuracy_score(full_gts, full_preds)\n",
        "        mean_loss = np.mean(np.asarray(val_loss_list))\n",
        "        print('Total validation loss {} and Validation accuracy {} after {} epochs'.format(mean_loss, mean_acc, epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi0DAtGGncLE",
        "outputId": "7b5064b3-5b89-44d7-a5b0-b91ba51331be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 2.2551025458744594 and training Accuracy 0.1218077474892396 after 0 epochs\n",
            "Total validation loss 2.248920624596732 and Validation accuracy 0.1400286944045911 after 0 epochs\n",
            "2\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 2.207627180644444 and training Accuracy 0.1466284074605452 after 1 epochs\n",
            "Total validation loss 2.2061667374202183 and Validation accuracy 0.1473457675753228 after 1 epochs\n",
            "3\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 2.175761944907052 and training Accuracy 0.16685796269727404 after 2 epochs\n",
            "Total validation loss 2.209117388725281 and Validation accuracy 0.13773314203730272 after 2 epochs\n",
            "4\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 2.1252242139407564 and training Accuracy 0.1896700143472023 after 3 epochs\n",
            "Total validation loss 2.0407844764845713 and Validation accuracy 0.21434720229555237 after 3 epochs\n",
            "5\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.9887996894972666 and training Accuracy 0.2543758967001435 after 4 epochs\n",
            "Total validation loss 2.015996854645865 and Validation accuracy 0.29899569583931135 after 4 epochs\n",
            "6\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.871391601221902 and training Accuracy 0.3236728837876614 after 5 epochs\n",
            "Total validation loss 1.9176026054791042 and Validation accuracy 0.29655667144906744 after 5 epochs\n",
            "7\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.7951175877026149 and training Accuracy 0.3581061692969871 after 6 epochs\n",
            "Total validation loss 1.8854938183512007 and Validation accuracy 0.31076040172166425 after 6 epochs\n",
            "8\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.700089258807046 and training Accuracy 0.4067431850789096 after 7 epochs\n",
            "Total validation loss 1.9285872851099286 and Validation accuracy 0.2956958393113343 after 7 epochs\n",
            "9\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.5930723530905588 and training Accuracy 0.4434720229555237 after 8 epochs\n",
            "Total validation loss 1.7063531586102076 and Validation accuracy 0.3814921090387374 after 8 epochs\n",
            "10\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.5432776519230433 and training Accuracy 0.4644189383070301 after 9 epochs\n",
            "Total validation loss 1.5951058523995536 and Validation accuracy 0.43242467718794836 after 9 epochs\n",
            "11\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.4014084850038802 and training Accuracy 0.5172166427546628 after 10 epochs\n",
            "Total validation loss 1.6309724807739259 and Validation accuracy 0.415351506456241 after 10 epochs\n",
            "12\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.3277471099581037 and training Accuracy 0.5464849354375897 after 11 epochs\n",
            "Total validation loss 1.5055206741605487 and Validation accuracy 0.48923959827833574 after 11 epochs\n",
            "13\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.229982832499913 and training Accuracy 0.5857962697274032 after 12 epochs\n",
            "Total validation loss 1.3727355480194092 and Validation accuracy 0.5473457675753228 after 12 epochs\n",
            "14\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.1547855649675642 and training Accuracy 0.6055954088952654 after 13 epochs\n",
            "Total validation loss 1.2042011192866735 and Validation accuracy 0.5779053084648493 after 13 epochs\n",
            "15\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.1100913669381822 and training Accuracy 0.6299856527977045 after 14 epochs\n",
            "Total validation loss 1.3070157323564802 and Validation accuracy 0.5311334289813486 after 14 epochs\n",
            "16\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 1.0378074884414672 and training Accuracy 0.6507890961262554 after 15 epochs\n",
            "Total validation loss 1.1375200305666242 and Validation accuracy 0.6464849354375897 after 15 epochs\n",
            "17\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.9710859068802424 and training Accuracy 0.6748923959827834 after 16 epochs\n",
            "Total validation loss 1.0155265816620418 and Validation accuracy 0.6807747489239598 after 16 epochs\n",
            "18\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.9447521618434361 and training Accuracy 0.6840746054519369 after 17 epochs\n",
            "Total validation loss 1.0484266740935189 and Validation accuracy 0.6661406025824964 after 17 epochs\n",
            "19\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.8646420759814126 and training Accuracy 0.7073170731707317 after 18 epochs\n",
            "Total validation loss 0.8884537671293531 and Validation accuracy 0.7124820659971306 after 18 epochs\n",
            "20\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.844002205984933 and training Accuracy 0.7137733142037302 after 19 epochs\n",
            "Total validation loss 0.9424978699002947 and Validation accuracy 0.6902439024390243 after 19 epochs\n",
            "21\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.794952278477805 and training Accuracy 0.7329985652797705 after 20 epochs\n",
            "Total validation loss 0.9663484147616795 and Validation accuracy 0.6639885222381635 after 20 epochs\n",
            "22\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.8023486128875188 and training Accuracy 0.7354375896700144 after 21 epochs\n",
            "Total validation loss 0.9818218180111477 and Validation accuracy 0.646054519368723 after 21 epochs\n",
            "23\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.7209684486900058 and training Accuracy 0.7611190817790531 after 22 epochs\n",
            "Total validation loss 0.8033062917845589 and Validation accuracy 0.7185078909612626 after 22 epochs\n",
            "24\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.7037955399070467 and training Accuracy 0.7637015781922525 after 23 epochs\n",
            "Total validation loss 0.7357848789010729 and Validation accuracy 0.7738880918220947 after 23 epochs\n",
            "25\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.6845902906996864 and training Accuracy 0.7718794835007173 after 24 epochs\n",
            "Total validation loss 0.7660505950450898 and Validation accuracy 0.7621233859397417 after 24 epochs\n",
            "26\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.6624216786452702 and training Accuracy 0.7757532281205165 after 25 epochs\n",
            "Total validation loss 0.7225801272051675 and Validation accuracy 0.7704447632711621 after 25 epochs\n",
            "27\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.640227267571858 and training Accuracy 0.7912482065997131 after 26 epochs\n",
            "Total validation loss 0.7529299437999726 and Validation accuracy 0.7621233859397417 after 26 epochs\n",
            "28\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.5702484841857638 and training Accuracy 0.8098995695839312 after 27 epochs\n",
            "Total validation loss 0.7587131542818887 and Validation accuracy 0.7350071736011478 after 27 epochs\n",
            "29\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.6046667886631829 and training Accuracy 0.8015781922525108 after 28 epochs\n",
            "Total validation loss 0.6535108715295792 and Validation accuracy 0.7863701578192253 after 28 epochs\n",
            "30\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.5396104846681867 and training Accuracy 0.8205164992826399 after 29 epochs\n",
            "Total validation loss 0.6452698673520769 and Validation accuracy 0.7806312769010043 after 29 epochs\n",
            "31\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 "
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(epoch+1)\n",
        "    train(dataloader_train, epoch)\n",
        "    validation(dataloader_val, epoch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = '/content/drive/My Drive/10_lang_wav_files/saved_final_model_epoch3.pth'\n",
        "state_dict = torch.load(model_save_path)\n",
        "model.load_state_dict(state_dict['model'])\n",
        "optimizer.load_state_dict(state_dict['optimizer'])\n",
        "epoch = state_dict['epoch']"
      ],
      "metadata": {
        "id": "8StDAelMXsq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(30, num_epochs):\n",
        "    print(epoch+1)\n",
        "    train(dataloader_train, epoch)\n",
        "    validation(dataloader_val, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xkz4LZSlXs7m",
        "outputId": "9ae4f0a6-2788-432a-f510-64d9dad8521d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.48038682213851386 and training Accuracy 0.8461979913916786 after 30 epochs\n",
            "Total validation loss 0.6831744841166905 and Validation accuracy 0.7773314203730273 after 30 epochs\n",
            "32\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.4446802628891809 and training Accuracy 0.8592539454806313 after 31 epochs\n",
            "Total validation loss 0.6788057110139302 and Validation accuracy 0.7747489239598279 after 31 epochs\n",
            "33\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.41189250626734325 and training Accuracy 0.8692969870875179 after 32 epochs\n",
            "Total validation loss 0.5746541138206209 and Validation accuracy 0.8094691535150645 after 32 epochs\n",
            "34\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.4323576673865318 and training Accuracy 0.8622668579626973 after 33 epochs\n",
            "Total validation loss 0.38228935322591234 and Validation accuracy 0.8985652797704448 after 33 epochs\n",
            "35\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.3701417105538504 and training Accuracy 0.878909612625538 after 34 epochs\n",
            "Total validation loss 0.38137374435152327 and Validation accuracy 0.8949784791965567 after 34 epochs\n",
            "36\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.35853018377508433 and training Accuracy 0.8901004304160689 after 35 epochs\n",
            "Total validation loss 0.5121559905154365 and Validation accuracy 0.8489239598278335 after 35 epochs\n",
            "37\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.31620077299220223 and training Accuracy 0.8974175035868006 after 36 epochs\n",
            "Total validation loss 0.46245534121990206 and Validation accuracy 0.8449067431850789 after 36 epochs\n",
            "38\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.3231738729136331 and training Accuracy 0.8952654232424677 after 37 epochs\n",
            "Total validation loss 0.3541450896433422 and Validation accuracy 0.8923959827833573 after 37 epochs\n",
            "39\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.2890621121440615 and training Accuracy 0.9070301291248206 after 38 epochs\n",
            "Total validation loss 0.4344593580280032 and Validation accuracy 0.8691535150645624 after 38 epochs\n",
            "40\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.29424715020826886 and training Accuracy 0.9047345767575323 after 39 epochs\n",
            "Total validation loss 0.38123540920870647 and Validation accuracy 0.8888091822094691 after 39 epochs\n",
            "41\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.25319524833134244 and training Accuracy 0.9170731707317074 after 40 epochs\n",
            "Total validation loss 0.3705396479793957 and Validation accuracy 0.8826398852223817 after 40 epochs\n",
            "42\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.27086121163197924 and training Accuracy 0.9119081779053084 after 41 epochs\n",
            "Total validation loss 0.37056941517761777 and Validation accuracy 0.8903873744619799 after 41 epochs\n",
            "43\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.2573793166450092 and training Accuracy 0.9137733142037303 after 42 epochs\n",
            "Total validation loss 0.31936139230217253 and Validation accuracy 0.9040172166427547 after 42 epochs\n",
            "44\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.25731309652328493 and training Accuracy 0.9143472022955523 after 43 epochs\n",
            "Total validation loss 0.42053716693605697 and Validation accuracy 0.861119081779053 after 43 epochs\n",
            "45\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.23020025012748582 and training Accuracy 0.9243902439024391 after 44 epochs\n",
            "Total validation loss 0.33263156775917324 and Validation accuracy 0.8885222381635581 after 44 epochs\n",
            "46\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.21640149993555888 and training Accuracy 0.9298421807747489 after 45 epochs\n",
            "Total validation loss 0.3543440791113036 and Validation accuracy 0.8832137733142037 after 45 epochs\n",
            "47\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.24133389783757073 and training Accuracy 0.9276901004304161 after 46 epochs\n",
            "Total validation loss 0.400910404750279 and Validation accuracy 0.8677187948350071 after 46 epochs\n",
            "48\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.231935453414917 and training Accuracy 0.927116212338594 after 47 epochs\n",
            "Total validation loss 0.3897701186793191 and Validation accuracy 0.893687230989957 after 47 epochs\n",
            "49\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.22046425161617142 and training Accuracy 0.9275466284074605 after 48 epochs\n",
            "Total validation loss 0.29413288831710815 and Validation accuracy 0.9196556671449068 after 48 epochs\n",
            "50\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.1967248293438128 and training Accuracy 0.9368723098995696 after 49 epochs\n",
            "Total validation loss 0.34496158084699086 and Validation accuracy 0.8822094691535151 after 49 epochs\n",
            "51\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.2298958542091506 and training Accuracy 0.9249641319942611 after 50 epochs\n",
            "Total validation loss 0.28867552557161874 and Validation accuracy 0.9203730272596844 after 50 epochs\n",
            "52\n",
            "batch: \n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 Total training loss 0.20345482943313462 and training Accuracy 0.9373027259684361 after 51 epochs\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c146e5-shGBG",
        "UmFsaK-ijzkT",
        "FZTJukZ0j4Nr"
      ],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}