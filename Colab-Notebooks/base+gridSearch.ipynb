{"cells":[{"cell_type":"markdown","metadata":{"id":"tyVD3AVqg_mT"},"source":["# **Model Version: 0.1 + gridsearch**\n"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6223,"status":"ok","timestamp":1684870358361,"user":{"displayName":"language project2","userId":"16722317159886808132"},"user_tz":-180},"id":"2vh7_3cunTO9","outputId":"66362651-8ba9-4079-8940-aff1b636d67b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"c146e5-shGBG"},"source":["### ***Imports***"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"zWtXTHyDhL1k","executionInfo":{"status":"ok","timestamp":1684870358361,"user_tz":-180,"elapsed":5,"user":{"displayName":"language project2","userId":"16722317159886808132"}}},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","import os\n","import numpy as np\n","import librosa\n","import random\n","from torch.utils.data import DataLoader\n","from torch import optim\n","import argparse\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"rcpi_IJdhLAL"},"source":["### **Models**"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"IA3-UdhFhCZN","executionInfo":{"status":"ok","timestamp":1684870358361,"user_tz":-180,"elapsed":4,"user":{"displayName":"language project2","userId":"16722317159886808132"}}},"outputs":[],"source":["class TDNN(nn.Module):\n","    \n","    def __init__(\n","                    self, \n","                    input_dim=23, \n","                    output_dim=512,\n","                    context_size=5,\n","                    stride=1,\n","                    dilation=1,\n","                    batch_norm=False,\n","                    dropout_p=0.2\n","                ):\n","        '''\n","        TDNN as defined by https://www.danielpovey.com/files/2015_interspeech_multisplice.pdf\n","\n","        Affine transformation not applied globally to all frames but smaller windows with local context\n","\n","        batch_norm: True to include batch normalisation after the non linearity\n","        \n","        Context size and dilation determine the frames selected\n","        (although context size is not really defined in the traditional sense)\n","        For example:\n","            context size 5 and dilation 1 is equivalent to [-2,-1,0,1,2]\n","            context size 3 and dilation 2 is equivalent to [-2, 0, 2]\n","            context size 1 and dilation 1 is equivalent to [0]\n","        '''\n","        super(TDNN, self).__init__()\n","        self.context_size = context_size\n","        self.stride = stride\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.dilation = dilation\n","        self.dropout_p = dropout_p\n","        self.batch_norm = batch_norm\n","      \n","        self.kernel = nn.Linear(input_dim*context_size, output_dim)\n","        self.nonlinearity = nn.ReLU()\n","        if self.batch_norm:\n","            self.bn = nn.BatchNorm1d(output_dim)\n","        if self.dropout_p:\n","            self.drop = nn.Dropout(p=self.dropout_p)\n","        \n","    def forward(self, x):\n","        '''\n","        input: size (batch, seq_len, input_features)\n","        outpu: size (batch, new_seq_len, output_features)\n","        '''\n","        \n","        _, _, d = x.shape\n","        assert (d == self.input_dim), 'Input dimension was wrong. Expected ({}), got ({})'.format(self.input_dim, d)\n","        x = x.unsqueeze(1)\n","\n","        # Unfold input into smaller temporal contexts\n","        x = F.unfold(\n","                        x, \n","                        (self.context_size, self.input_dim), \n","                        stride=(1,self.input_dim), \n","                        dilation=(self.dilation,1)\n","                    )\n","\n","        # N, output_dim*context_size, new_t = x.shape\n","        x = x.transpose(1,2)\n","        x = self.kernel(x.float())\n","        x = self.nonlinearity(x)\n","        \n","        if self.dropout_p:\n","            x = self.drop(x)\n","\n","        if self.batch_norm:\n","            x = x.transpose(1,2)\n","            x = self.bn(x)\n","            x = x.transpose(1,2)\n","\n","        return x"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"GhX96WM1hbCD","executionInfo":{"status":"ok","timestamp":1684870364946,"user_tz":-180,"elapsed":771,"user":{"displayName":"language project2","userId":"16722317159886808132"}}},"outputs":[],"source":["class X_vector(nn.Module):\n","    # changed for grid-search starts\n","    def __init__(self, input_dim = 40, num_classes=8, context_size_layer_1=5, dilation_layer_1=1, context_size_layer_2=3, dilation_layer_2=1, context_size_layer_3=2, dilation_layer_3=2):\n","        super(X_vector, self).__init__()\n","        i_d = input_dim\n","        self.tdnn1 = TDNN(input_dim=i_d, output_dim=512, context_size=context_size_layer_1, dilation=dilation_layer_1, dropout_p=0.5)\n","        self.tdnn2 = TDNN(input_dim=512, output_dim=512, context_size=context_size_layer_2, dilation=dilation_layer_2, dropout_p=0.5)\n","        self.tdnn3 = TDNN(input_dim=512, output_dim=512, context_size=context_size_layer_3, dilation=dilation_layer_3, dropout_p=0.5)\n","    # changed for grid-search end\n","        self.tdnn4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1,dropout_p=0.5)\n","        self.tdnn5 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=3,dropout_p=0.5)\n","        #### Frame levelPooling\n","        self.segment6 = nn.Linear(1024, 512)\n","        self.segment7 = nn.Linear(512, 512)\n","        self.output = nn.Linear(512, num_classes)\n","        self.softmax = nn.Softmax(dim=1)\n","    def forward(self, inputs):\n","        tdnn1_out = self.tdnn1(inputs)\n","        return tdnn1_out\n","        tdnn2_out = self.tdnn2(tdnn1_out)\n","        tdnn3_out = self.tdnn3(tdnn2_out)\n","        tdnn4_out = self.tdnn4(tdnn3_out)\n","        tdnn5_out = self.tdnn5(tdnn4_out)\n","        ### Stat Pool\n","        mean = torch.mean(tdnn5_out,1)\n","        std = torch.std(tdnn5_out,1)\n","        stat_pooling = torch.cat((mean,std),1)\n","        segment6_out = self.segment6(stat_pooling)\n","        x_vec = self.segment7(segment6_out)\n","        predictions = self.softmax(self.output(x_vec))\n","        return predictions,x_vec"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"yiZdP05khlC3","executionInfo":{"status":"ok","timestamp":1684870367499,"user_tz":-180,"elapsed":4,"user":{"displayName":"language project2","userId":"16722317159886808132"}}},"outputs":[],"source":["class X_vector(nn.Module):\n","  # changed for grid-search starts\n","    def __init__(self, input_dim = 40, num_classes=8, context_size_layer_1=5, dilation_layer_1=1, context_size_layer_2=3, dilation_layer_2=1, context_size_layer_3=2, dilation_layer_3=2):\n","        super(X_vector, self).__init__()\n","        i_d = input_dim\n","        self.tdnn1 = TDNN(input_dim=i_d, output_dim=512, context_size=context_size_layer_1, dilation=dilation_layer_1, dropout_p=0.5)\n","        self.tdnn2 = TDNN(input_dim=512, output_dim=512, context_size=context_size_layer_2, dilation=dilation_layer_2, dropout_p=0.5)\n","        self.tdnn3 = TDNN(input_dim=512, output_dim=512, context_size=context_size_layer_3, dilation=dilation_layer_3, dropout_p=0.5)\n","  # changed for grid-search end\n","        self.tdnn4 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=1, dropout_p=0.5)\n","        self.tdnn5 = TDNN(input_dim=512, output_dim=512, context_size=1, dilation=3, dropout_p=0.5)\n","        #### Frame levelPooling\n","        self.segment6 = nn.Linear(1024, 512)\n","        self.segment7 = nn.Linear(512, 512)\n","        self.output = nn.Linear(512, num_classes)\n","        self.softmax = nn.Softmax(dim=1)\n","    def forward(self, inputs):\n","        tdnn1_out = self.tdnn1(inputs)\n","        tdnn2_out = self.tdnn2(tdnn1_out)\n","        tdnn3_out = self.tdnn3(tdnn2_out)\n","        tdnn4_out = self.tdnn4(tdnn3_out)\n","        tdnn5_out = self.tdnn5(tdnn4_out)\n","        ### Stat Pool\n","        \n","        mean = torch.mean(tdnn5_out,1)\n","        std = torch.var(tdnn5_out,1)\n","        stat_pooling = torch.cat((mean,std),1)\n","        segment6_out = self.segment6(stat_pooling)\n","        x_vec = self.segment7(segment6_out)\n","        predictions = self.output(x_vec)\n","        return predictions,x_vec"]},{"cell_type":"markdown","metadata":{"id":"UmFsaK-ijzkT"},"source":["### Utiles "]},{"cell_type":"code","execution_count":42,"metadata":{"id":"gV8XI7_4jUAH","executionInfo":{"status":"ok","timestamp":1684870369839,"user_tz":-180,"elapsed":7,"user":{"displayName":"language project2","userId":"16722317159886808132"}}},"outputs":[],"source":["def load_wav(audio_filepath, sr, min_dur_sec=4):\n","    audio_data,fs  = librosa.load(audio_filepath,sr=16000)\n","    len_file = len(audio_data)\n","    \n","    if len_file <int(min_dur_sec*sr):\n","        dummy=np.zeros((1,int(min_dur_sec*sr)-len_file))\n","        extened_wav = np.concatenate((audio_data,dummy[0]))\n","    else:\n","        \n","        extened_wav = audio_data\n","    return extened_wav\n","\n","\n","def lin_mel_from_wav(wav, hop_length, win_length, n_mels):\n","    linear = librosa.feature.melspectrogram(wav, n_mels=n_mels, win_length=win_length, hop_length=hop_length) # linear spectrogram\n","    return linear.T\n","\n","def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=512):\n","    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length) # linear spectrogram\n","    return linear.T\n","\n","\n","def feature_extraction(filepath,sr=16000, min_dur_sec=4,win_length=400,hop_length=160, n_mels=40, spec_len=400,mode='train'):\n","    audio_data = load_wav(filepath, sr=sr,min_dur_sec=min_dur_sec)\n","    linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_fft=512)\n","    mag, _ = librosa.magphase(linear_spect)  # magnitude\n","    mag_T = mag.T\n","    mu = np.mean(mag_T, 0, keepdims=True)\n","    std = np.std(mag_T, 0, keepdims=True)\n","    return (mag_T - mu) / (std + 1e-5)\n","    \n","    \n","    \n","    \n","def load_data(filepath,sr=16000, min_dur_sec=4,win_length=400,hop_length=160, n_mels=40, spec_len=400,mode='train'):\n","    audio_data = load_wav(filepath, sr=sr,min_dur_sec=min_dur_sec)\n","    #linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_mels)\n","    linear_spect = lin_spectogram_from_wav(audio_data, hop_length, win_length, n_fft=512)\n","    mag, _ = librosa.magphase(linear_spect)  # magnitude\n","    mag_T = mag.T\n","    \n","    if mode=='train':\n","        randtime = np.random.randint(0, mag_T.shape[1]-spec_len)\n","        spec_mag = mag_T[:, randtime:randtime+spec_len]\n","    else:\n","        spec_mag = mag_T\n","    \n","    # preprocessing, subtract mean, divided by time-wise var\n","    mu = np.mean(spec_mag, 0, keepdims=True)\n","    std = np.std(spec_mag, 0, keepdims=True)\n","    return (spec_mag - mu) / (std + 1e-5)\n","    \n","\n","\n","def load_npy_data(filepath,spec_len=400,mode='train'):\n","    mag_T = np.load(filepath)\n","    if mode=='train':\n","        randtime = np.random.randint(0, mag_T.shape[1]-spec_len)\n","        spec_mag = mag_T[:, randtime:randtime+spec_len]\n","    else:\n","        spec_mag = mag_T\n","    return spec_mag\n","    \n","    \n","\n","\n","\n","def speech_collate(batch):\n","    targets = []\n","    specs = []\n","    for sample in batch:\n","        specs.append(sample['features'])\n","        targets.append((sample['labels']))\n","    return specs, targets"]},{"cell_type":"markdown","metadata":{"id":"FZTJukZ0j4Nr"},"source":["## SpeechDataGenerator"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"gjvylivejY_y","executionInfo":{"status":"ok","timestamp":1684870372757,"user_tz":-180,"elapsed":6,"user":{"displayName":"language project2","userId":"16722317159886808132"}}},"outputs":[],"source":["class SpeechDataGenerator():\n","    \"\"\"Speech dataset.\"\"\"\n","\n","    def __init__(self, manifest, mode):\n","        \"\"\"\n","        Read the textfile and get the paths\n","        \"\"\"\n","        \n","        # [line.rstrip('\\n').split(' ')[0]\n","        self.mode=mode\n","        self.audio_links = [\" \".join(line.rstrip('\\n').split(' ')[:-1]) for line in open(manifest)]\n","        self.labels = [int(line.rstrip('\\n').split(' ')[-1]) for line in open(manifest)]\n","        \n","\n","    def __len__(self):\n","        return len(self.audio_links)\n","\n","    def __getitem__(self, idx):\n","        audio_link =self.audio_links[idx]\n","        class_id = self.labels[idx]\n","        #lang_label=lang_id[self.audio_links[idx].split('/')[-2]]\n","        spec = load_data(audio_link,mode=self.mode)\n","        sample = {'features': torch.from_numpy(np.ascontiguousarray(spec)), 'labels': torch.from_numpy(np.ascontiguousarray(class_id))}\n","        return sample"]},{"cell_type":"markdown","metadata":{"id":"iZM6lFNOlwL6"},"source":["## Train X Vector"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"idauk9yWlyJs","executionInfo":{"status":"error","timestamp":1684870454101,"user_tz":-180,"elapsed":21,"user":{"displayName":"language project2","userId":"16722317159886808132"}},"colab":{"base_uri":"https://localhost:8080/","height":433},"outputId":"37efcfed-847c-4273-e509-821d8086f992"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-ee74e1239bf2>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.98\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mloss_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["torch.multiprocessing.set_sharing_strategy('file_system')\n","\n","training_filepath = '/content/drive/My Drive/10_lang_wav_files/train_10_lang.txt'\n","testing_filepath = '/content/drive/My Drive/10_lang_wav_files/test_10_lang.txt'\n","validation_filepath = '/content/drive/My Drive/10_lang_wav_files/validation_10_lang.txt'\n","input_dim = 257\n","num_classes = 10\n","lamda_val = 0.5\n","batch_size = 10\n","use_gpu = True\n","num_epochs = 100\n","\n","### Data related\n","dataset_train = SpeechDataGenerator(manifest=training_filepath, mode='train')\n","dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n","\n","dataset_val = SpeechDataGenerator(manifest=validation_filepath, mode='train')\n","dataloader_val = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n","\n","dataset_test = SpeechDataGenerator(manifest=testing_filepath, mode='test')\n","dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n","\n","## Model related\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = X_vector(input_dim, num_classes).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)\n","loss_fun = nn.CrossEntropyLoss()\n","\n","\n","def train(dataloader_train, epoch):\n","    train_loss_list = []\n","    full_preds = []\n","    full_gts = []\n","    model.train()\n","\n","    for i_batch, sample_batched in enumerate(dataloader_train):\n","        print(\"batch: \" + str(i_batch+1))\n","        features = torch.from_numpy(np.asarray([torch_tensor.numpy().T for torch_tensor in sample_batched[0]])).float()\n","        labels = torch.from_numpy(np.asarray([torch_tensor[0].numpy() for torch_tensor in sample_batched[1]]))\n","        labels = labels.long()\n","        features, labels = features.to(device), labels.to(device)\n","        features.requires_grad = True\n","        optimizer.zero_grad()\n","        pred_logits, x_vec = model(features)\n","        #### CE loss\n","        loss = loss_fun(pred_logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss_list.append(loss.item())\n","        # train_acc_list.append(accuracy)\n","        # if i_batch%10==0:\n","        #    print('Loss {} after {} iteration'.format(np.mean(np.asarray(train_loss_list)),i_batch))\n","\n","        predictions = np.argmax(pred_logits.detach().cpu().numpy(), axis=1)\n","        for pred in predictions:\n","            full_preds.append(pred)\n","        for lab in labels.detach().cpu().numpy():\n","            full_gts.append(lab)\n","\n","    mean_acc = accuracy_score(full_gts, full_preds)\n","    mean_loss = np.mean(np.asarray(train_loss_list))\n","    print('Total training loss {} and training Accuracy {} after {} epochs'.format(mean_loss, mean_acc, epoch))\n","\n","\n","def validation(dataloader_val, epoch):\n","    model.eval()\n","    with torch.no_grad():\n","        val_loss_list = []\n","        full_preds = []\n","        full_gts = []\n","        for i_batch, sample_batched in enumerate(dataloader_val):\n","            features = torch.from_numpy(\n","                np.asarray([torch_tensor.numpy().T for torch_tensor in sample_batched[0]])).float()\n","            labels = torch.from_numpy(np.asarray([torch_tensor[0].numpy() for torch_tensor in sample_batched[1]]))\n","            labels = labels.long()\n","            features, labels = features.to(device), labels.to(device)\n","            pred_logits, x_vec = model(features)\n","            #### CE loss\n","            loss = loss_fun(pred_logits, labels)\n","            val_loss_list.append(loss.item())\n","            # train_acc_list.append(accuracy)\n","            predictions = np.argmax(pred_logits.detach().cpu().numpy(), axis=1)\n","            for pred in predictions:\n","                full_preds.append(pred)\n","            for lab in labels.detach().cpu().numpy():\n","                full_gts.append(lab)\n","\n","        mean_acc = accuracy_score(full_gts, full_preds)\n","        mean_loss = np.mean(np.asarray(val_loss_list))\n","        print('Total validation loss {} and Validation accuracy {} after {} epochs'.format(mean_loss, mean_acc, epoch))\n","\n","        # TODO: CHANGE BACK TO SAVE MODEL:\n","        # model_save_path = os.path.join('save_model', 'best_check_point_' + str(epoch) + '_' + str(mean_loss))\n","        # state_dict = {'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}\n","        # torch.save(state_dict, model_save_path)"]},{"cell_type":"code","source":["# ### Data related\n","# dataset_train = SpeechDataGenerator(manifest=training_filepath, mode='train')\n","# dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n","\n","# dataset_val = SpeechDataGenerator(manifest=validation_filepath, mode='train')\n","# dataloader_val = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n","\n","# dataset_test = SpeechDataGenerator(manifest=testing_filepath, mode='test')\n","# dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, collate_fn=speech_collate)\n","\n","# ## Model related\n","# use_cuda = torch.cuda.is_available()\n","# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","# # model = X_vector(input_dim, num_classes).to(device)\n","# # optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)\n","# # loss_fun = nn.CrossEntropyLoss()"],"metadata":{"id":"uj-0HgYkGojo","executionInfo":{"status":"ok","timestamp":1684870036802,"user_tz":-180,"elapsed":12,"user":{"displayName":"language project2","userId":"16722317159886808132"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"elapsed":564,"status":"error","timestamp":1684870042278,"user":{"displayName":"language project2","userId":"16722317159886808132"},"user_tz":-180},"id":"qi0DAtGGncLE","outputId":"803659b2-6c5c-4974-ac1a-8bc05c5889ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training with context_size=2 and dilation=1\n","\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-8017011b5092>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Initialize the model with the current hyperparameters for layer 1 (only!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# TODO: change to 3 layers in some way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_size_layer_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_layer_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.98\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mloss_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["#gridSearch start:\n","\n","import itertools\n","num_epochs = 5\n","\n","context_sizes = [2, 3, 5, 7]\n","dilations = [1, 2, 3]\n","\n","best_accuracy = 0.0\n","best_hyperparams = None\n","hyperparameters_list = []\n","accuracy_and_loss_list = []\n","\n","for context_size, dilation in itertools.product(context_sizes, dilations):\n","    print()\n","    print(f'Training with context_size={context_size} and dilation={dilation}')\n","    print()\n","\n","    # Initialize the model with the current hyperparameters for layer 1 (only!)\n","    # TODO: change to 3 layers in some way\n","    model = X_vector(input_dim, num_classes, context_size_layer_1=context_size, dilation_layer_1=dilation).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)\n","    loss_fun = nn.CrossEntropyLoss()\n","\n","    # Train and validate the model\n","    for epoch in range(num_epochs):\n","        print(\"epoch: \" + str(epoch))\n","        train(dataloader_train, epoch)\n","        accuracy_and_loss = validation(dataloader_val, epoch)\n","        \n","\n","        if accuracy_and_loss[0] > best_accuracy:\n","            best_accuracy = accuracy_and_loss[0]\n","            best_hyperparams = (context_size, dilation)\n","    \n","    print(f'hyperparameters (context_size,dilation): ={hyperparameters_list}, accuracy={accuracy_and_loss_list}')\n","    hyperparameters_list.append((context_size, dilation))\n","    accuracy_and_loss_list.append(accuracy_and_loss)\n","\n","\n","print(f'Best hyperparameters: context_size={best_hyperparams[0]}, dilation={best_hyperparams[1]}, '\n","      f'validation accuracy={best_accuracy}')\n","\n","print(f'hyperparameters (context_size,dilation): ={hyperparameters_list}, accuracy={accuracy_and_loss_list}')\n","\n","#gridSearch end"]},{"cell_type":"code","source":["# import itertools\n","# import concurrent.futures\n","# import os\n","# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","\n","# num_epochs = 100\n","# context_sizes = [2, 3, 5, 7]\n","# dilations = [1, 2, 3]\n","\n","# best_accuracy = 0.0\n","# best_hyperparams = None\n","# hyperparameters_list = []\n","# accuracy_and_loss_list = []\n","\n","# def train_and_validate(context_size, dilation):\n","#     global best_accuracy\n","#     global best_hyperparams\n","\n","#     print()\n","#     print(f'Training with context_size={context_size} and dilation={dilation}')\n","#     print()\n","\n","#     # Initialize the model with the current hyperparameters for layer 1 (only!)\n","#     # TODO: change to 3 layers in some way\n","#     model = X_vector(input_dim, num_classes, context_size_layer_1=context_size, dilation_layer_1=dilation).to(device)\n","#     optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0, betas=(0.9, 0.98), eps=1e-9)\n","#     loss_fun = nn.CrossEntropyLoss()\n","\n","#     # Train and validate the model\n","#     for epoch in range(num_epochs):\n","#         # print(\"epoch: \" + str(epoch))\n","#         train(model, optimizer, loss_fun, dataloader_train, epoch)\n","#         accuracy_and_loss = validation(model, loss_fun, dataloader_val, epoch)\n","\n","#         if accuracy_and_loss[0] > best_accuracy:\n","#             best_accuracy = accuracy_and_loss[0]\n","#             best_hyperparams = (context_size, dilation)\n","\n","#     return (context_size, dilation, accuracy_and_loss)\n","\n","# # Create a thread pool with a maximum of 4 threads\n","# with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n","#     futures = []\n","#     for context_size, dilation in itertools.product(context_sizes, dilations):\n","#         futures.append(executor.submit(train_and_validate, context_size, dilation))\n","\n","#     for future in concurrent.futures.as_completed(futures):\n","#         result = future.result()\n","#         hyperparameters_list.append((result[0], result[1]))\n","#         accuracy_and_loss_list.append(result[2])\n","#         print(f'hyperparameters (context_size,dilation): {hyperparameters_list}, accuracy: {accuracy_and_loss_list}')\n","\n","# print(f'Best hyperparameters: context_size={best_hyperparams[0]}, dilation={best_hyperparams[1]}, '\n","#       f'validation accuracy={best_accuracy}')\n","\n","# print(f'hyperparameters (context_size,dilation): {hyperparameters_list}, accuracy: {accuracy_and_loss_list}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"hZYL5ya0SYAk","executionInfo":{"status":"error","timestamp":1684869445533,"user_tz":-180,"elapsed":2105,"user":{"displayName":"language project2","userId":"16722317159886808132"}},"outputId":"26cec4af-ea48-4124-dca3-703aa935a279"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training with context_size=2 and dilation=1\n","\n","\n","Training with context_size=2 and dilation=2\n","\n","\n","Training with context_size=2 and dilation=3\n","\n","\n","Training with context_size=3 and dilation=1\n","\n","\n","Training with context_size=3 and dilation=2\n","\n","\n","Training with context_size=3 and dilation=3\n","\n","\n","\n","Training with context_size=5 and dilation=2\n","\n","Training with context_size=5 and dilation=1\n","\n","\n","Training with context_size=5 and dilation=3\n","\n","\n","Training with context_size=7 and dilation=1\n","\n","\n","Training with context_size=7 and dilation=2\n","\n","\n","Training with context_size=7 and dilation=3\n","\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-0569594c615e>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mhyperparameters_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0maccuracy_and_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-0569594c615e>\u001b[0m in \u001b[0;36mtrain_and_validate\u001b[0;34m(context_size, dilation)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Initialize the model with the current hyperparameters for layer 1 (only!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# TODO: change to 3 layers in some way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_size_layer_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_layer_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.98\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"18V_N4eQGlQwWoG1AbLJQLQC7eZFp85VA","timestamp":1684332689615}],"collapsed_sections":["rcpi_IJdhLAL","UmFsaK-ijzkT","FZTJukZ0j4Nr"]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}